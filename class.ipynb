{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process corpora in classic pipeline\n",
    "\n",
    "1. Tokenization\n",
    "2. Vectorization\n",
    "3. TF-IDF\n",
    "4. Hyperparameter optimization\n",
    "5. Training\n",
    "6. Evaluation\n",
    "\n",
    "Classic algorithms are:\n",
    "- Random\n",
    "- Naïve Bayes\n",
    "- Logistic Regression\n",
    "- Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = list()\n",
    "\n",
    "for corpus in {\"wikipedia\", \"dramen\", \"zeitung\", \"romane\"}:\n",
    "    score = dict(classification.classic_pipeline(corpus))\n",
    "    score = pd.Series(score)\n",
    "    score.name = corpus.capitalize()\n",
    "    scores.append(score)\n",
    "\n",
    "scores = pd.DataFrame(scores).round(4).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dramen</th>\n",
       "      <th>Romane</th>\n",
       "      <th>Wikipedia</th>\n",
       "      <th>Zeitung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.3544</td>\n",
       "      <td>0.3544</td>\n",
       "      <td>0.3544</td>\n",
       "      <td>0.3544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.6709</td>\n",
       "      <td>0.6203</td>\n",
       "      <td>0.9241</td>\n",
       "      <td>0.7975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.7215</td>\n",
       "      <td>0.7089</td>\n",
       "      <td>0.9114</td>\n",
       "      <td>0.7848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Dramen  Romane  Wikipedia  Zeitung\n",
       "Random                  0.3544  0.3544     0.3544   0.3544\n",
       "Logistic Regression     0.6709  0.6203     0.9241   0.7975\n",
       "Support Vector Machine  0.7215  0.7089     0.9114   0.7848"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.loc[:, [\"Dramen\", \"Romane\", \"Wikipedia\", \"Zeitung\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process corpora in neural pipeline\n",
    "\n",
    "1. Tokenization\n",
    "2. Fine-tuning\n",
    "6. Evaluation\n",
    "\n",
    "Neural models are:\n",
    "- German BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [\"wikipedia\", \"romane\", \"zeitung\", \"dramen\"]:\n",
    "    df = downsample(classification.preprocessing.load(x))\n",
    "    import json\n",
    "    with open(f\"{x}-downsampled.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps([{\"class\": row[\"class\"], \"text\": row[\"text\"]} for _, row in df.iterrows()], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(dataset, ratio={0: 296, 1: 304, 2: 181}):\n",
    "    a = dataset[dataset[\"class\"] == 0].reset_index()\n",
    "    b = dataset[dataset[\"class\"] == 1].reset_index()\n",
    "    c = dataset[dataset[\"class\"] == 2].reset_index()\n",
    "        \n",
    "    a_ = random.sample(range(a.shape[0]), ratio[0])\n",
    "    b_ = random.sample(range(b.shape[0]), ratio[1])\n",
    "    c_ = random.sample(range(c.shape[0]), ratio[2])\n",
    "    \n",
    "    a = a.iloc[a.index.isin(a_)]\n",
    "    b = b.iloc[b.index.isin(b_)]\n",
    "    c = c.iloc[c.index.isin(c_)]\n",
    "    return a.append(b).append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_class</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Liebste Lisel, mein Vergnügen,\\nDu mein Herz, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Sie muß wissen, daß wir drey zusammen als Bube...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Fragst du das, weil du selbst ein gelernter Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Ich bin einverstanden – du kannst deine Rolle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Entsetzlich viel. Heute kommen die zwey Amante...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Fast wie ein Wolf, der Lämmer frißt,\\nder schn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Da stecket etwas dahinter – ein liebenswürdige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Ich bitte unterthänig, mir mit meiner Geschlec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>suchen Sie Ihren Fall wieder gut zu machen, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Ganz geheim und in der Still\\nWollen wir uns l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Bis hieher geht alles so, wie ich wünsche und ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Eben steckt er in dem Rauchfange von diesem Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Schätzbarester Herr von Wolf! ich bitte, erzäh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>beede Gnädige üb ertrefen in der Aussprache un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Quesio core sta per voi,\\nNe dividerlo vorrei:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Ich werde ihr einige Kleidungsstücke für den V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Ein zahmes Reh, welches Beyde für ihren Unterh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Nun dann, so stellen Sie sich vor, Sie sind hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Saget mir: Ach! sagt mir gleich:\\nWer Ihr seyd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Wenigst – mir scheint es so – unsre Amour – si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Nun sind wir in der Gelegenheit, seine geheime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Euer Gnaden belieben mit mir ihrer gnädiger Sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>bleibt Lisel der Köchinn mir. \\n Ich gratulire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>ist die gnädiger Frau junge schöne Wittib; hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>500 Dukaten soll ich gleich erlegen? bey seine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Dieser Briefele muß an die Lisel Köchinn abgeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Er schreibt zwey Briefe in meinem Zimmer, und ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>Ja – aber – wenn Sie mich bey dem Volpino und ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>da durfte ich mich auf Befehl meines Volpino n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Komödie</td>\n",
       "      <td>0</td>\n",
       "      <td>die That verdient ein Preise\\nUnserer Erkenntl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13294</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Johann Wolfgang Goethe\\nDes Epimenides Erwache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13295</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Die Fesseln fallen ab von Händ' und Füßen,\\nWi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Und diesen lass' ich euch an meiner Stelle,\\nD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Sobald ihr scherzend kommt,\\nDann ist es Ernst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Er reicht ihnen die Hände, welche sie anfassen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Des Höchsten bin ich mir bewußt,\\nDem Wunderba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>So geht es kühn\\nZur Welt hinein;\\nWas wir bez...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Fürwahr, dein ungezähmter Mut\\nLäßt sich durch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13302</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>HOFMANN. \\n\\nDoch alles, was wir je ersonnen,\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13303</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>In das Feste sucht zu dringen\\nUngewaltsam, oh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13304</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Ich werde niemals dir verwehren,\\nZu schaun me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13305</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Zu dringen und zu weichen,\\nDas ist die größte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13306</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Ja, ich schweife schon im Weiten\\nDieser Wildn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Liebe fährt in ihrem heitern Gesange noch eine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13308</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>DÄMON DER UNTERDRÜCKUNG\\n\\nzur Liebe. \\n\\n\\nWi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13309</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Doch wie ist mir! von Medusen\\nWerd' ich greul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13310</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>DÄMON DER UNTERDRÜCKUNG. \\n\\nSie kommt! sie is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13311</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Die breite Wolke senkt sich, eine Wolke\\nLeben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13312</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>ich wanke, sinke hier,\\nHabe nicht mehr Kraft ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13313</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Immer sind wir noch im Lande,\\nHier und dort m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13314</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Im Tiefsten hohl, das Erdreich untergraben,\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13315</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Nun begegn' ich meinen Braven,\\nDie sich in de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13316</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Er erwacht, regt sich, steht auf, tritt unter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13317</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Es ist der Schöpfung wildes Chaos hier,\\nDas l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>EPIMENIDES. \\n\\nDämonen seid ihr, keine Genien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13319</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>So erschallt nun Gottes Stimme,\\nDenn des Volk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13320</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Auftritt\\n\\n\\n\\n\\nAchter Auftritt\\n\\nGlaube un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13321</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>PRIESTER. \\n\\nTadle nicht der Götter Willen,\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13322</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Die Tugenden, die hier ein kräftig Wirken\\nUnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13323</th>\n",
       "      <td>Schauspiel</td>\n",
       "      <td>2</td>\n",
       "      <td>Euch zu laben,\\nLaßt uns eilen,\\nUnsre Gaben\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13324 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           _class  class                                               text\n",
       "0         Komödie      0  Liebste Lisel, mein Vergnügen,\\nDu mein Herz, ...\n",
       "1         Komödie      0  Sie muß wissen, daß wir drey zusammen als Bube...\n",
       "2         Komödie      0  Fragst du das, weil du selbst ein gelernter Mu...\n",
       "3         Komödie      0  Ich bin einverstanden – du kannst deine Rolle ...\n",
       "4         Komödie      0  Entsetzlich viel. Heute kommen die zwey Amante...\n",
       "5         Komödie      0  Fast wie ein Wolf, der Lämmer frißt,\\nder schn...\n",
       "6         Komödie      0  Da stecket etwas dahinter – ein liebenswürdige...\n",
       "7         Komödie      0  Ich bitte unterthänig, mir mit meiner Geschlec...\n",
       "8         Komödie      0  suchen Sie Ihren Fall wieder gut zu machen, we...\n",
       "9         Komödie      0  Ganz geheim und in der Still\\nWollen wir uns l...\n",
       "10        Komödie      0  Bis hieher geht alles so, wie ich wünsche und ...\n",
       "11        Komödie      0  Eben steckt er in dem Rauchfange von diesem Ka...\n",
       "12        Komödie      0  Schätzbarester Herr von Wolf! ich bitte, erzäh...\n",
       "13        Komödie      0  beede Gnädige üb ertrefen in der Aussprache un...\n",
       "14        Komödie      0  Quesio core sta per voi,\\nNe dividerlo vorrei:...\n",
       "15        Komödie      0  Ich werde ihr einige Kleidungsstücke für den V...\n",
       "16        Komödie      0  Ein zahmes Reh, welches Beyde für ihren Unterh...\n",
       "17        Komödie      0  Nun dann, so stellen Sie sich vor, Sie sind hi...\n",
       "18        Komödie      0  Saget mir: Ach! sagt mir gleich:\\nWer Ihr seyd...\n",
       "19        Komödie      0  Wenigst – mir scheint es so – unsre Amour – si...\n",
       "20        Komödie      0  Nun sind wir in der Gelegenheit, seine geheime...\n",
       "21        Komödie      0  Euer Gnaden belieben mit mir ihrer gnädiger Sp...\n",
       "22        Komödie      0  bleibt Lisel der Köchinn mir. \\n Ich gratulire...\n",
       "23        Komödie      0  ist die gnädiger Frau junge schöne Wittib; hat...\n",
       "24        Komödie      0  500 Dukaten soll ich gleich erlegen? bey seine...\n",
       "25        Komödie      0  Dieser Briefele muß an die Lisel Köchinn abgeg...\n",
       "26        Komödie      0  Er schreibt zwey Briefe in meinem Zimmer, und ...\n",
       "27        Komödie      0  Ja – aber – wenn Sie mich bey dem Volpino und ...\n",
       "28        Komödie      0  da durfte ich mich auf Befehl meines Volpino n...\n",
       "29        Komödie      0  die That verdient ein Preise\\nUnserer Erkenntl...\n",
       "...           ...    ...                                                ...\n",
       "13294  Schauspiel      2  Johann Wolfgang Goethe\\nDes Epimenides Erwache...\n",
       "13295  Schauspiel      2  Die Fesseln fallen ab von Händ' und Füßen,\\nWi...\n",
       "13296  Schauspiel      2  Und diesen lass' ich euch an meiner Stelle,\\nD...\n",
       "13297  Schauspiel      2  Sobald ihr scherzend kommt,\\nDann ist es Ernst...\n",
       "13298  Schauspiel      2  Er reicht ihnen die Hände, welche sie anfassen...\n",
       "13299  Schauspiel      2  Des Höchsten bin ich mir bewußt,\\nDem Wunderba...\n",
       "13300  Schauspiel      2  So geht es kühn\\nZur Welt hinein;\\nWas wir bez...\n",
       "13301  Schauspiel      2  Fürwahr, dein ungezähmter Mut\\nLäßt sich durch...\n",
       "13302  Schauspiel      2  HOFMANN. \\n\\nDoch alles, was wir je ersonnen,\\...\n",
       "13303  Schauspiel      2  In das Feste sucht zu dringen\\nUngewaltsam, oh...\n",
       "13304  Schauspiel      2  Ich werde niemals dir verwehren,\\nZu schaun me...\n",
       "13305  Schauspiel      2  Zu dringen und zu weichen,\\nDas ist die größte...\n",
       "13306  Schauspiel      2  Ja, ich schweife schon im Weiten\\nDieser Wildn...\n",
       "13307  Schauspiel      2  Liebe fährt in ihrem heitern Gesange noch eine...\n",
       "13308  Schauspiel      2  DÄMON DER UNTERDRÜCKUNG\\n\\nzur Liebe. \\n\\n\\nWi...\n",
       "13309  Schauspiel      2  Doch wie ist mir! von Medusen\\nWerd' ich greul...\n",
       "13310  Schauspiel      2  DÄMON DER UNTERDRÜCKUNG. \\n\\nSie kommt! sie is...\n",
       "13311  Schauspiel      2  Die breite Wolke senkt sich, eine Wolke\\nLeben...\n",
       "13312  Schauspiel      2  ich wanke, sinke hier,\\nHabe nicht mehr Kraft ...\n",
       "13313  Schauspiel      2  Immer sind wir noch im Lande,\\nHier und dort m...\n",
       "13314  Schauspiel      2  Im Tiefsten hohl, das Erdreich untergraben,\\nA...\n",
       "13315  Schauspiel      2  Nun begegn' ich meinen Braven,\\nDie sich in de...\n",
       "13316  Schauspiel      2  Er erwacht, regt sich, steht auf, tritt unter ...\n",
       "13317  Schauspiel      2  Es ist der Schöpfung wildes Chaos hier,\\nDas l...\n",
       "13318  Schauspiel      2  EPIMENIDES. \\n\\nDämonen seid ihr, keine Genien...\n",
       "13319  Schauspiel      2  So erschallt nun Gottes Stimme,\\nDenn des Volk...\n",
       "13320  Schauspiel      2  Auftritt\\n\\n\\n\\n\\nAchter Auftritt\\n\\nGlaube un...\n",
       "13321  Schauspiel      2  PRIESTER. \\n\\nTadle nicht der Götter Willen,\\n...\n",
       "13322  Schauspiel      2  Die Tugenden, die hier ein kräftig Wirken\\nUnd...\n",
       "13323  Schauspiel      2  Euch zu laben,\\nLaßt uns eilen,\\nUnsre Gaben\\n...\n",
       "\n",
       "[13324 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{\"class\": row[\"class\"], \"text\": row[\"text\"]} for _, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-26 16:39:44,322 Reading data from classification/data/flair/split\n",
      "2019-08-26 16:39:44,323 Train: classification/data/flair/split/romane-train-flair.txt\n",
      "2019-08-26 16:39:44,324 Dev: classification/data/flair/split/romane-val-flair.txt\n",
      "2019-08-26 16:39:44,325 Test: classification/data/flair/split/romane-test-flair.txt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ClassificationCorpus\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import TREC_6\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = 'classification/data/flair/split'\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus: Corpus = ClassificationCorpus(data_folder,\n",
    "                                      test_file='romane-test-flair.txt',\n",
    "                                      dev_file='romane-val-flair.txt',\n",
    "                                      train_file='romane-train-flair.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"» Siehe , wozu mich heute der Gehorsam verdammt .\" - 10 Tokens"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-26 16:39:46,966 {'1', '2', '0'}\n"
     ]
    }
   ],
   "source": [
    "# 2. create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary()\n",
    "\n",
    "# 3. make a list of word embeddings\n",
    "word_embeddings = [WordEmbeddings('de'),\n",
    "\n",
    "                   # comment in flair embeddings for state-of-the-art results\n",
    "                   # FlairEmbeddings('news-forward'),\n",
    "                   # FlairEmbeddings('news-backward'),\n",
    "                   ]\n",
    "\n",
    "# 4. initialize document embedding by passing list of word embeddings\n",
    "# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n",
    "document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n",
    "                                                                     hidden_size=512,\n",
    "                                                                     reproject_words=True,\n",
    "                                                                     reproject_words_dimension=256,\n",
    "                                                                     )\n",
    "\n",
    "# 5. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
    "\n",
    "# 6. initialize the text classifier trainer\n",
    "trainer = ModelTrainer(classifier, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-26 16:40:03,633 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-26 16:40:03,635 Evaluation method: MICRO_F1_SCORE\n",
      "2019-08-26 16:40:04,006 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-26 16:40:05,042 epoch 1 - iter 0/40 - loss 1.11759722\n",
      "2019-08-26 16:40:08,518 epoch 1 - iter 4/40 - loss 1.05342314\n",
      "2019-08-26 16:40:10,916 epoch 1 - iter 8/40 - loss 1.04623997\n",
      "2019-08-26 16:40:13,449 epoch 1 - iter 12/40 - loss 1.03089637\n",
      "2019-08-26 16:40:16,801 epoch 1 - iter 16/40 - loss 1.02999891\n",
      "2019-08-26 16:40:20,782 epoch 1 - iter 20/40 - loss 1.03822716\n",
      "2019-08-26 16:40:24,940 epoch 1 - iter 24/40 - loss 1.03750018\n",
      "2019-08-26 16:40:28,639 epoch 1 - iter 28/40 - loss 1.03812209\n",
      "2019-08-26 16:40:31,201 epoch 1 - iter 32/40 - loss 1.03477837\n",
      "2019-08-26 16:40:34,554 epoch 1 - iter 36/40 - loss 1.03636513\n",
      "2019-08-26 16:40:37,087 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-26 16:40:37,089 EPOCH 1 done: loss 1.0369 - lr 0.1000 - bad epochs 0\n",
      "2019-08-26 16:40:38,240 DEV : loss 0.9985542297363281 - score 0.5106\n",
      "2019-08-26 16:40:39,102 TEST : loss 0.9844071269035339 - score 0.5669\n",
      "2019-08-26 16:41:09,263 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-26 16:41:10,869 epoch 2 - iter 0/40 - loss 1.02978170\n",
      "2019-08-26 16:41:13,585 epoch 2 - iter 4/40 - loss 0.98021522\n",
      "2019-08-26 16:41:18,374 epoch 2 - iter 8/40 - loss 0.98469243\n",
      "2019-08-26 16:41:21,262 epoch 2 - iter 12/40 - loss 0.99983498\n",
      "2019-08-26 16:41:26,760 epoch 2 - iter 16/40 - loss 0.99654941\n",
      "2019-08-26 16:41:30,019 epoch 2 - iter 20/40 - loss 1.00460073\n",
      "2019-08-26 16:41:33,679 epoch 2 - iter 24/40 - loss 1.00478654\n",
      "2019-08-26 16:41:36,554 epoch 2 - iter 28/40 - loss 1.00640896\n",
      "2019-08-26 16:41:40,181 epoch 2 - iter 32/40 - loss 1.00087469\n",
      "2019-08-26 16:41:43,702 epoch 2 - iter 36/40 - loss 0.99718519\n",
      "2019-08-26 16:41:46,929 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-26 16:41:46,931 EPOCH 2 done: loss 1.0019 - lr 0.1000 - bad epochs 0\n",
      "2019-08-26 16:41:48,078 DEV : loss 0.9712680578231812 - score 0.5106\n",
      "2019-08-26 16:41:49,109 TEST : loss 0.9559522867202759 - score 0.586\n",
      "2019-08-26 16:42:39,959 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-26 16:42:45,602 epoch 3 - iter 0/40 - loss 0.88809913\n",
      "2019-08-26 16:42:48,984 epoch 3 - iter 4/40 - loss 0.96773523\n",
      "2019-08-26 16:42:51,439 epoch 3 - iter 8/40 - loss 0.95101506\n",
      "2019-08-26 16:42:54,721 epoch 3 - iter 12/40 - loss 0.95896451\n",
      "2019-08-26 16:42:57,109 epoch 3 - iter 16/40 - loss 0.95801327\n",
      "2019-08-26 16:43:00,204 epoch 3 - iter 20/40 - loss 0.95936264\n",
      "2019-08-26 16:43:03,330 epoch 3 - iter 24/40 - loss 0.96239455\n",
      "2019-08-26 16:43:07,952 epoch 3 - iter 28/40 - loss 0.97351066\n",
      "2019-08-26 16:43:11,542 epoch 3 - iter 32/40 - loss 0.96499128\n",
      "2019-08-26 16:43:13,702 epoch 3 - iter 36/40 - loss 0.96970478\n",
      "2019-08-26 16:43:16,172 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-26 16:43:16,173 EPOCH 3 done: loss 0.9775 - lr 0.1000 - bad epochs 1\n",
      "2019-08-26 16:43:17,025 DEV : loss 0.9803107380867004 - score 0.4894\n",
      "2019-08-26 16:43:17,848 TEST : loss 0.9717399477958679 - score 0.4777\n",
      "2019-08-26 16:43:17,849 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-26 16:43:19,288 epoch 4 - iter 0/40 - loss 0.90970403\n",
      "2019-08-26 16:43:22,215 epoch 4 - iter 4/40 - loss 0.95811803\n",
      "2019-08-26 16:43:25,071 epoch 4 - iter 8/40 - loss 0.97705319\n",
      "2019-08-26 16:43:29,598 epoch 4 - iter 12/40 - loss 0.99178579\n",
      "2019-08-26 16:43:32,902 epoch 4 - iter 16/40 - loss 0.98758762\n",
      "2019-08-26 16:43:36,326 epoch 4 - iter 20/40 - loss 0.97810776\n",
      "2019-08-26 16:43:38,584 epoch 4 - iter 24/40 - loss 0.98010489\n",
      "2019-08-26 16:43:42,222 epoch 4 - iter 28/40 - loss 0.97442928\n",
      "2019-08-26 16:43:44,442 epoch 4 - iter 32/40 - loss 0.96268754\n",
      "2019-08-26 16:43:46,524 epoch 4 - iter 36/40 - loss 0.95907518\n",
      "2019-08-26 16:43:48,511 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-26 16:43:48,512 EPOCH 4 done: loss 0.9632 - lr 0.1000 - bad epochs 2\n",
      "2019-08-26 16:43:49,345 DEV : loss 0.9514826536178589 - score 0.5532\n",
      "2019-08-26 16:43:50,147 TEST : loss 0.9458789825439453 - score 0.535\n",
      "2019-08-26 16:44:10,929 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-26 16:44:12,848 epoch 5 - iter 0/40 - loss 0.98820728\n",
      "2019-08-26 16:44:14,989 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-26 16:44:14,990 Exiting from training early.\n",
      "2019-08-26 16:44:14,991 Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/severin/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, evaluation_metric, learning_rate, mini_batch_size, eval_mini_batch_size, max_epochs, anneal_factor, patience, train_with_dev, monitor_train, embeddings_in_memory, checkpoint, save_final_model, anneal_with_restarts, shuffle, param_selection_mode, num_workers, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a0f9047a90f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0manneal_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m               max_epochs=5)\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, evaluation_metric, learning_rate, mini_batch_size, eval_mini_batch_size, max_epochs, anneal_factor, patience, train_with_dev, monitor_train, embeddings_in_memory, checkpoint, save_final_model, anneal_with_restarts, shuffle, param_selection_mode, num_workers, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam_selection_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving model ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"final-model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/flair/nn.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, model_file)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     def save_checkpoint(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_id\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# https://docs.python.org/2/library/pickle.html#pickling-and-unpickling-external-objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# https://github.com/python/cpython/blob/master/Lib/pickle.py#L527-L537\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mserialized_container_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 7. start the training\n",
    "trainer.train('test-zeitung',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,\n",
    "              max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for file in Path(\"classification/data\").glob(\"**/*.json\"):\n",
    "    preprocessing.convert_flair_data(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification import preprocessing\n",
    "\n",
    "dataset = preprocessing.load(corpus, split=True)\n",
    "if downsample:\n",
    "    dataset = preprocessing.downsample(dataset)\n",
    "\n",
    "train_data = [\n",
    "    (row[\"text\"], {\"class\": {\"A\": row[\"_class\"]}})\n",
    "    for _, row in dataset[\"train\"].iterrows()\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for name, model in [(\"BERT\", \"de_pytt_bertbasecased_lg\")]:\n",
    "    nlp = spacy.load(model)\n",
    "    c = nlp.create_pipe(\"classification\")\n",
    "    nlp.add_pipe(c, last=True)\n",
    "    textcat.add_label(\"A\")\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(epochs):\n",
    "        for doc, gold in train_data:\n",
    "            nlp.update([doc], [gold], sgd=optimizer)\n",
    "\n",
    "doc = nlp(u\"It is good.\")\n",
    "print(doc.cats)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = preprocessing.load(corpus, split=False)\n",
    "if downsample:\n",
    "    dataset = preprocessing.downsample(dataset)\n",
    "vectorizer = TfidfVectorizer(tokenizer=preprocessing.tokenize, max_features=10000)\n",
    "X, y = vectorizer.fit_transform(dataset[\"text\"]), list(dataset[\"class\"])\n",
    "X, y = preprocessing.split(X, y, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification import preprocessing\n",
    "\n",
    "dataset = preprocessing.load(\"zeitung\", split=True)\n",
    "X = dataset[\"train\"][\"text\"]\n",
    "y = dataset[\"train\"][\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = list(zip(X, [{\"cats\": yy} for yy in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = preprocessing.load(\"dramen\", split=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    59\n",
       "1    47\n",
       "2    33\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"de\")\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencizer', 'pytt_wordpiecer', 'pytt_tok2vec']\n",
      "Loaded model 'de_pytt_bertbasecased_lg'\n",
      "Labels: ('0', '1', '2')\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n"
     ]
    }
   ],
   "source": [
    "def cyclic_triangular_rate(min_lr, max_lr, period):\n",
    "    it = 1\n",
    "    while True:\n",
    "        # https://towardsdatascience.com/adaptive-and-cyclical-learning-rates-using-pytorch-2bf904d18dee\n",
    "        cycle = numpy.floor(1 + it / (2 * period))\n",
    "        x = numpy.abs(it / period - 2 * cycle + 1)\n",
    "        relative = max(0, 1 - x)\n",
    "        yield min_lr + (max_lr - min_lr) * relative\n",
    "        it += 1\n",
    "\n",
    "import numpy\n",
    "import spacy\n",
    "from collections import Counter\n",
    "learn_rate=2e-5\n",
    "batch_size=8\n",
    "model=\"de_pytt_bertbasecased_lg\"\n",
    "LABELS = [\"0\", \"1\", \"2\"]\n",
    "\n",
    "\n",
    "spacy.util.fix_random_seed(23)\n",
    "\n",
    "nlp = spacy.load(model)\n",
    "print(nlp.pipe_names)\n",
    "print(f\"Loaded model '{model}'\")\n",
    "textcat = nlp.create_pipe(\n",
    "    \"pytt_textcat\", config={\"architecture\": \"softmax_last_hidden\", \"nr_class\": 3}\n",
    ")\n",
    "for label in LABELS:\n",
    "    textcat.add_label(label)\n",
    "    \n",
    "X = dataset[\"train\"][\"text\"]\n",
    "y = dataset[\"train\"][\"class\"]\n",
    "\n",
    "train_data = list(zip(X, [{\"cats\": {\"0\": 1 if yy == 0 else 0, \"1\": 1 if yy == 1 else 0, \"2\": 1 if yy == 2 else 0}} for yy in y]))\n",
    "    \n",
    "print(\"Labels:\", textcat.labels)\n",
    "nlp.add_pipe(textcat, last=True)\n",
    "\n",
    "optimizer = nlp.resume_training()\n",
    "optimizer.alpha = 0.001\n",
    "optimizer.pytt_weight_decay = 0.005\n",
    "optimizer.L2 = 0.0\n",
    "learn_rates = cyclic_triangular_rate(\n",
    "    learn_rate / 3, learn_rate * 3, 2 * len(train_data) // batch_size\n",
    ")\n",
    "print(\"Training the model...\")\n",
    "print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
    "\n",
    "results = []\n",
    "epoch = 0\n",
    "step = 0\n",
    "eval_every = 100\n",
    "patience = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n",
      "({'cats': '0'}, {'cats': '1'}, {'cats': '2'}, {'cats': '1'}, {'cats': '1'}, {'cats': '1'}, {'cats': '0'}, {'cats': '0'})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 1; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-372b29c6eba9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/spacy_pytorch_transformers/language.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGoldParse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoldParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mnew_docs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mnew_golds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mgold.pyx\u001b[0m in \u001b[0;36mspacy.gold.GoldParse.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 1; 2 is required"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from spacy.util import minibatch\n",
    "\n",
    "while True:\n",
    "    print(\"epoch\")\n",
    "    # Train and evaluate\n",
    "    losses = Counter()\n",
    "    random.shuffle(train_data)\n",
    "    batches = minibatch(train_data, size=batch_size)\n",
    "    for batch in batches:\n",
    "        optimizer.pytt_lr = next(learn_rates)\n",
    "        texts, annotations = zip(*batch)\n",
    "        print(annotations)\n",
    "        nlp.update(texts, annotations, sgd=optimizer, drop=0.1, losses=losses)\n",
    "        step += 1\n",
    "    epoch += 1\n",
    "    # Stop if no improvement in HP.patience checkpoints\n",
    "    if results:\n",
    "        best_score, best_step, best_epoch = max(results)\n",
    "        if ((step - best_step) // eval_every) >= patience:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.375"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X )/ 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msg = wasabi.Printer()\n",
    "table_widths = [2, 4, 6]\n",
    "msg.info(f\"Best scoring checkpoints\")\n",
    "msg.row([\"Epoch\", \"Step\", \"Score\"], widths=table_widths)\n",
    "msg.row([\"-\" * width for width in table_widths])\n",
    "for score, step, epoch in sorted(results, reverse=True)[:10]:\n",
    "    msg.row([epoch, step, \"%.2f\" % (score * 100)], widths=table_widths)\n",
    "\n",
    "# Test the trained model\n",
    "test_text = eval_texts[0]\n",
    "doc = nlp(test_text)\n",
    "print(test_text, doc.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wiener Oberlandesgericht leistete der Beschwer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Neue Veröffentlichung des österreichischen Mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Einem deutsch-österreichisches Forscherteam ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Der Schweizer wurde 76 Jahre alt. Frankfurt – ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Zwergspitz sollte mit Spedition geliefert werd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Noch ist unklar, ob es sich dabei tatsächlich ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Lucia Plank vermisst unseren Planeten mithilfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Nu Couche\" wechselte für mehr als 170 Million...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Derzeit keine Folgeschäden absehbar. Irdning –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Wien – Hunde gehen rascher zu fremden Objekten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Siebenjähriger wurde leicht verletzt. Turrache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Drei Beruhigungsspritzen betäubten Tier – 20 F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>Die österreichische Fußball-Nationalmannschaft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>Neues Flüchtlingsunglück vor Samos. Lesbos – B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>In einem Forschungszentrum für Primatologie un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>Mit 30.000 Euro dotiert – Autoren müssen ihre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>51-jähriger mit Bissverletzungen an Unterarmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>Eine Wiener Kunsthistorikerin hat erstmals säm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>Welche Bücher befinden sich aktuell auf Ihrer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>Mit Grenzgängen zwischen Schlager und Subversi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>Ähnlichkeiten zwischen \"Million Years Ago\" und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>Fairbanks – Bisher ging man davon aus, dass di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>Werner Schwabs \"Fäkaliendrama\" als famose Musi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>Wiederaufnahmeantrag der Polizei wurde abgewie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>Den Lieblingsfilm in einem Satz zu erzählen is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>In einem Wiener Sicherheitsprojekt wird erfors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>Geschworene verwarfen Mordanklage – 28-Jährige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>Allein zuständiger Beamter ist überfordert, Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>Das Frankfurter Städel-Museum widmet sich in d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>Eine 78-Jährige ist nach über 50 Jahren mit ih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>In seinem neuen Kabarettprogramm \"Der Tolerato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2</td>\n",
       "      <td>Thomas Henzinger erhält den Milner Award 2015 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2</td>\n",
       "      <td>Teilchenphysiker Valentin Knünz erforscht schw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>5.700 kamen am Mittwoch in Slowenien an – Ein ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>Der Mythen- und Religionsforscher wurde 91 Jah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>Laut Sprecher der Staatsanwaltschaft \"Kein Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>Prägte unverkennbaren Grundton des Artemis Qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Die Nacht, als ich sie sah\": Der slowenische ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2</td>\n",
       "      <td>Oberösterreichische Forscher entwickeln ein Sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0</td>\n",
       "      <td>Die großartigste Hommage an den Dramatiker Hei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1</td>\n",
       "      <td>In Ungarn sind Flüchtlinge unerwünscht. Dennoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>Vom nächtlichen Leben mit einem Gipsarm. Danke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>Peter Pakesch, Vorsitzender der von der Künstl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>Nach Abkommen mit der Türkei könnten weitere F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1</td>\n",
       "      <td>Ein 19-Jähriger soll zwei Unmündige vergewalti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2</td>\n",
       "      <td>Platz 27 auf der Liste bekannter Rekord-Rohdia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>Bereits 3.000 Menschen um 6 Uhr angekommen, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2</td>\n",
       "      <td>Bis Ende Juli sollen 100 Wale getötet werden. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>Im Nahverkehrsbereich waren es laut Bahnstatis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>Türkeis Ministerpräsident warnt vor einer \"chr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1</td>\n",
       "      <td>Trotz Störungszone am Mittwoch teilweise Tempe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0</td>\n",
       "      <td>Ob er in die übergroßen Fußstapfen seines Vorg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>Diese Woche interessieren wir uns nicht nur da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>Das Helene-Fischer-Vokabular vor dem Ernst-Hap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>Edler Gesang, greller Humor: Donizettis \"Don P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2</td>\n",
       "      <td>Zwei Forschungsteams untersuchten, wie Stammze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>Syrerin im Rücken getroffen. Bratislava/Wien –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>Opfer brach seinem Peiniger die Nase – Tatverd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>Auftritt am 9.5. in die Wiener Stadthalle – Vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>\"La Rondine\" in der Regie von Rolando Villazon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                               text\n",
       "0        1  Wiener Oberlandesgericht leistete der Beschwer...\n",
       "1        2  Neue Veröffentlichung des österreichischen Mat...\n",
       "2        2  Einem deutsch-österreichisches Forscherteam ge...\n",
       "3        0  Der Schweizer wurde 76 Jahre alt. Frankfurt – ...\n",
       "4        1  Zwergspitz sollte mit Spedition geliefert werd...\n",
       "5        2  Noch ist unklar, ob es sich dabei tatsächlich ...\n",
       "6        2  Lucia Plank vermisst unseren Planeten mithilfe...\n",
       "7        0  \"Nu Couche\" wechselte für mehr als 170 Million...\n",
       "8        1  Derzeit keine Folgeschäden absehbar. Irdning –...\n",
       "9        2  Wien – Hunde gehen rascher zu fremden Objekten...\n",
       "10       1  Siebenjähriger wurde leicht verletzt. Turrache...\n",
       "11       1  Drei Beruhigungsspritzen betäubten Tier – 20 F...\n",
       "12       2  Die österreichische Fußball-Nationalmannschaft...\n",
       "13       1  Neues Flüchtlingsunglück vor Samos. Lesbos – B...\n",
       "14       2  In einem Forschungszentrum für Primatologie un...\n",
       "15       0  Mit 30.000 Euro dotiert – Autoren müssen ihre ...\n",
       "16       1  51-jähriger mit Bissverletzungen an Unterarmen...\n",
       "17       2  Eine Wiener Kunsthistorikerin hat erstmals säm...\n",
       "18       0  Welche Bücher befinden sich aktuell auf Ihrer ...\n",
       "19       0  Mit Grenzgängen zwischen Schlager und Subversi...\n",
       "20       0  Ähnlichkeiten zwischen \"Million Years Ago\" und...\n",
       "21       2  Fairbanks – Bisher ging man davon aus, dass di...\n",
       "22       0  Werner Schwabs \"Fäkaliendrama\" als famose Musi...\n",
       "23       1  Wiederaufnahmeantrag der Polizei wurde abgewie...\n",
       "24       0  Den Lieblingsfilm in einem Satz zu erzählen is...\n",
       "25       2  In einem Wiener Sicherheitsprojekt wird erfors...\n",
       "26       1  Geschworene verwarfen Mordanklage – 28-Jährige...\n",
       "27       1  Allein zuständiger Beamter ist überfordert, Hi...\n",
       "28       0  Das Frankfurter Städel-Museum widmet sich in d...\n",
       "29       1  Eine 78-Jährige ist nach über 50 Jahren mit ih...\n",
       "..     ...                                                ...\n",
       "109      0  In seinem neuen Kabarettprogramm \"Der Tolerato...\n",
       "110      2  Thomas Henzinger erhält den Milner Award 2015 ...\n",
       "111      2  Teilchenphysiker Valentin Knünz erforscht schw...\n",
       "112      1  5.700 kamen am Mittwoch in Slowenien an – Ein ...\n",
       "113      0  Der Mythen- und Religionsforscher wurde 91 Jah...\n",
       "114      1  Laut Sprecher der Staatsanwaltschaft \"Kein Fre...\n",
       "115      0  Prägte unverkennbaren Grundton des Artemis Qua...\n",
       "116      0  \"Die Nacht, als ich sie sah\": Der slowenische ...\n",
       "117      2  Oberösterreichische Forscher entwickeln ein Sy...\n",
       "118      0  Die großartigste Hommage an den Dramatiker Hei...\n",
       "119      1  In Ungarn sind Flüchtlinge unerwünscht. Dennoc...\n",
       "120      0  Vom nächtlichen Leben mit einem Gipsarm. Danke...\n",
       "121      0  Peter Pakesch, Vorsitzender der von der Künstl...\n",
       "122      1  Nach Abkommen mit der Türkei könnten weitere F...\n",
       "123      1  Ein 19-Jähriger soll zwei Unmündige vergewalti...\n",
       "124      2  Platz 27 auf der Liste bekannter Rekord-Rohdia...\n",
       "125      1  Bereits 3.000 Menschen um 6 Uhr angekommen, we...\n",
       "126      2  Bis Ende Juli sollen 100 Wale getötet werden. ...\n",
       "127      1  Im Nahverkehrsbereich waren es laut Bahnstatis...\n",
       "128      1  Türkeis Ministerpräsident warnt vor einer \"chr...\n",
       "129      1  Trotz Störungszone am Mittwoch teilweise Tempe...\n",
       "130      0  Ob er in die übergroßen Fußstapfen seines Vorg...\n",
       "131      0  Diese Woche interessieren wir uns nicht nur da...\n",
       "132      0  Das Helene-Fischer-Vokabular vor dem Ernst-Hap...\n",
       "133      0  Edler Gesang, greller Humor: Donizettis \"Don P...\n",
       "134      2  Zwei Forschungsteams untersuchten, wie Stammze...\n",
       "135      1  Syrerin im Rücken getroffen. Bratislava/Wien –...\n",
       "136      1  Opfer brach seinem Peiniger die Nase – Tatverd...\n",
       "137      0  Auftritt am 9.5. in die Wiener Stadthalle – Vo...\n",
       "138      0  \"La Rondine\" in der Regie von Rolando Villazon...\n",
       "\n",
       "[139 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.de import German\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic\n",
    "1. K-means\n",
    "2. Naive Bayes\n",
    "3. SVM\n",
    "\n",
    "### Deep Learning\n",
    "1. RoBERTa\n",
    "2. XLNet\n",
    "3. TransformerXL\n",
    "\n",
    "\n",
    "\n",
    "Jeweils angemessen große Stichprobe -> Mann-Whitney-U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = German()\n",
    "TOKENIZER = Tokenizer(nlp.vocab)\n",
    "\n",
    "def tokenize(document):\n",
    "    return [token.text for token in TOKENIZER(document)]\n",
    "\n",
    "\n",
    "def count_tokens(document):\n",
    "    return len(document)\n",
    "\n",
    "\n",
    "def count_types(document):\n",
    "    return len(set(document))\n",
    "\n",
    "\n",
    "def corpus_statistics(corpus):\n",
    "    tokens = corpus[\"text\"].apply(tokenize)\n",
    "    size = corpus.shape[0]\n",
    "    num_tokens = tokens.apply(count_tokens)\n",
    "    num_types = tokens.apply(count_types)\n",
    "    avg_length = round(num_tokens.mean(), 2)\n",
    "    std_length = round(num_tokens.std(), 2)\n",
    "    minimum = num_tokens.min()\n",
    "    maximum = num_tokens.max()\n",
    "    abs_class_dist = corpus[\"class\"].value_counts()\n",
    "    rel_class_dist = list(abs_class_dist / abs_class_dist.sum())\n",
    "    _flat_tokens = [token for document in tokens for token in document]\n",
    "    total_tokens = len(_flat_tokens)\n",
    "    total_types = len(set(_flat_tokens))\n",
    "    rel_num_tokens = num_tokens / num_tokens.sum()\n",
    "    rel_num_tokens.name = corpus.name\n",
    "    return rel_num_tokens, {\"corpus\": corpus.name, \"size\": size, \"tokens\": total_tokens,\n",
    "            \"types\": total_types, \"avg_length\": avg_length, \"std_length\": std_length,\n",
    "            \"minimum\": minimum, \"maximum\": maximum, \"rel_class_dist\": rel_class_dist, \"abs_class_dist\": list(abs_class_dist)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(filepath, max_features=10000):\n",
    "    return pd.read_json(filepath)\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenize, max_features=max_features)\n",
    "    return vectorizer.fit_transform(corpus[\"text\"]), corpus[\"class\"].tolist()\n",
    "\n",
    "def split_dataset(X, y, val=.15, test=.15, random_state=23):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test, random_state=random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val, random_state=random_state)\n",
    "    return {\"train\": X_train, \"val\": X_val, \"test\": X_test}, {\"train\": y_train, \"val\": y_val, \"test\": y_test}\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize, max_features=10000)\n",
    "class Cleaner(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf(\"../corpora/romane.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = split_dataset(x[\"text\"], x[\"class\"].replace(\"Komödie\", 0).replace(\"Tragödie\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list()\n",
    "b = list()\n",
    "\n",
    "for xx in [\"wikipedia\", \"zeitung\", \"romane\", \"dramen\"]:\n",
    "    corpus = classification.preprocessing.load(xx, split=False, downsample=True)\n",
    "    corpus.name = xx.title()\n",
    "    num_tokens, stats = corpus_statistics(corpus)\n",
    "    a.append(num_tokens)\n",
    "    b.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_class_dist</th>\n",
       "      <th>avg_length</th>\n",
       "      <th>corpus</th>\n",
       "      <th>maximum</th>\n",
       "      <th>minimum</th>\n",
       "      <th>rel_class_dist</th>\n",
       "      <th>size</th>\n",
       "      <th>std_length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[304, 296, 181]</td>\n",
       "      <td>108.46</td>\n",
       "      <td>Dramen</td>\n",
       "      <td>144</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.3892445582586428, 0.37900128040973113, 0.23...</td>\n",
       "      <td>781</td>\n",
       "      <td>15.50</td>\n",
       "      <td>84711</td>\n",
       "      <td>19867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[304, 296, 181]</td>\n",
       "      <td>89.45</td>\n",
       "      <td>Romane</td>\n",
       "      <td>290</td>\n",
       "      <td>19</td>\n",
       "      <td>[0.3892445582586428, 0.37900128040973113, 0.23...</td>\n",
       "      <td>781</td>\n",
       "      <td>38.22</td>\n",
       "      <td>69864</td>\n",
       "      <td>8724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[304, 296, 181]</td>\n",
       "      <td>117.06</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>150</td>\n",
       "      <td>35</td>\n",
       "      <td>[0.3892445582586428, 0.37900128040973113, 0.23...</td>\n",
       "      <td>781</td>\n",
       "      <td>20.43</td>\n",
       "      <td>91422</td>\n",
       "      <td>25972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[304, 296, 181]</td>\n",
       "      <td>119.41</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>204</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.3892445582586428, 0.37900128040973113, 0.23...</td>\n",
       "      <td>781</td>\n",
       "      <td>44.43</td>\n",
       "      <td>93263</td>\n",
       "      <td>26857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    abs_class_dist  avg_length     corpus  maximum  minimum  \\\n",
       "3  [304, 296, 181]      108.46     Dramen      144       20   \n",
       "2  [304, 296, 181]       89.45     Romane      290       19   \n",
       "0  [304, 296, 181]      117.06  Wikipedia      150       35   \n",
       "1  [304, 296, 181]      119.41    Zeitung      204       50   \n",
       "\n",
       "                                      rel_class_dist  size  std_length  \\\n",
       "3  [0.3892445582586428, 0.37900128040973113, 0.23...   781       15.50   \n",
       "2  [0.3892445582586428, 0.37900128040973113, 0.23...   781       38.22   \n",
       "0  [0.3892445582586428, 0.37900128040973113, 0.23...   781       20.43   \n",
       "1  [0.3892445582586428, 0.37900128040973113, 0.23...   781       44.43   \n",
       "\n",
       "   tokens  types  \n",
       "3   84711  19867  \n",
       "2   69864   8724  \n",
       "0   91422  25972  \n",
       "1   93263  26857  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(b).sort_values(\"corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.DataFrame(a).T\n",
    "s = s.loc[:, reversed([\"Dramen\", \"Romane\", \"Wikipedia\", \"Zeitung\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = s.plot.box(vert=False, color=\"black\", figsize=(8,3))\n",
    "ax.set_xlabel(\"Relative proportion of tokens in corpus, per document\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/home/severin/Downloads/corpus.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(b).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.loc[\"corpus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, [\"Dramen\", \"Romane\", \"Wikipedia\", \"Zeitung\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_csv(\"proportions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import operator\n",
    "directory = \"classification/data/full\"\n",
    "\n",
    "preprocessing.split_and_export(directory, downsample_corpus=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1[\"length\"] = corpus1[\"text\"].apply(len)\n",
    "corpus2[\"length\"] = corpus2[\"text\"].apply(len)\n",
    "dist = corpus2[\"class\"].value_counts()\n",
    "\n",
    "lengths = [group[\"length\"] for _, group in corpus2.groupby(\"class\")]\n",
    "\n",
    "\n",
    "downsampled = list()\n",
    "for _, group in corpus1.groupby(\"class\"):\n",
    "    group = group.sort_values(\"length\", ascending=False)\n",
    "    idx = dist[_]\n",
    "    cropped = [t[:lengths[_][i]] for i, t in enumerate(group[\"text\"][:idx])]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73\n",
       "1    57\n",
       "2    43\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(dataset, ratio=(73, 57, 43), random_state=23):\n",
    "    a, b, c = tuple(set(dataset[\"class\"]))\n",
    "    a = dataset[dataset[\"class\"] == a]\n",
    "    b = dataset[dataset[\"class\"] == b]\n",
    "    c = dataset[dataset[\"class\"] == c]\n",
    "    random.seed(random_state)\n",
    "    a_ = random.sample(list(a.index), ratio[0])\n",
    "    b_ = random.sample(list(b.index), ratio[1])\n",
    "    c_ = random.sample(list(b.index), ratio[2])\n",
    "    a = a.iloc[[True if _ in a_ else False for _ in a.index]]\n",
    "    b = b.iloc[[True if _ in b_ else False for _ in b.index]]\n",
    "    c = c.iloc[[True if _ in c_ else False for _ in c.index]]\n",
    "    return a.append(b).append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_class</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Der Nationalismus in Russland nehme ständig zu...</td>\n",
       "      <td>1732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>\"La Rondine\" in der Regie von Rolando Villazon...</td>\n",
       "      <td>2921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>47-jährige Dramaturgin folgt auf Bettina Herin...</td>\n",
       "      <td>1271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Die stillen Nächte des Ludwig Rainer\" feiert ...</td>\n",
       "      <td>2210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Uraufführung des österreichischen Dramatikers ...</td>\n",
       "      <td>2677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>In seinem neuen Kabarettprogramm \"Der Tolerato...</td>\n",
       "      <td>7630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Der fliegende Holländer\" im Theater an der Wi...</td>\n",
       "      <td>3002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Die \"Dreigroschenoper \" in der Regie von Keith...</td>\n",
       "      <td>3804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Edler Gesang, greller Humor: Donizettis \"Don P...</td>\n",
       "      <td>2249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Schwarzer Humor im Off-Theater: Das Bernhard-E...</td>\n",
       "      <td>3041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Werner Schwabs \"Fäkaliendrama\" als famose Musi...</td>\n",
       "      <td>4014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Sein \"Werther\"-Solo hat seit der Premiere 1974...</td>\n",
       "      <td>6752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Dusan David Parízek hat für seine Fassung von ...</td>\n",
       "      <td>3668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Vorzeichen für Inszenierung hätten sich aufgru...</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Anja Salomonowitz inszeniert im Volx/Margarete...</td>\n",
       "      <td>2948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Die großartigste Hommage an den Dramatiker Hei...</td>\n",
       "      <td>3940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Der 18-Jährige kam nahe dem Gelände des Sziget...</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Ob er in die übergroßen Fußstapfen seines Vorg...</td>\n",
       "      <td>2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Durch das Alpine Museum der Schweiz weht ein f...</td>\n",
       "      <td>5059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>In \"Der Nachtmahr\" erschafft der Filmemacher u...</td>\n",
       "      <td>6131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Drama, Herzschmerz, Hausaufgaben – der Mikroko...</td>\n",
       "      <td>2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Den Lieblingsfilm in einem Satz zu erzählen is...</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Nach vier glücklosen Anläufen bekam DiCaprio d...</td>\n",
       "      <td>6027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Oskar, Rico und Herzgebreche\" ist die Verfilm...</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>In Babak Najafis Actionspektakel mit Aaron Eck...</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Das Holocaustdrama von László Nemes, mit einem...</td>\n",
       "      <td>5167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Mit seinen klaren, schnörkellosen Filmen um ko...</td>\n",
       "      <td>3992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Ant-Man\" blieb vorn – \"Pixels\" und \"Minions\" ...</td>\n",
       "      <td>1799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Unterstützer der Sammlung Alter Musikinstrumen...</td>\n",
       "      <td>4554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Kultur</td>\n",
       "      <td>0</td>\n",
       "      <td>Hunderte Objekte illegal exportierten antiken ...</td>\n",
       "      <td>4127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Vier junge Tschetschenen forderten Mädchen auf...</td>\n",
       "      <td>4650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Drei Beruhigungsspritzen betäubten Tier – 20 F...</td>\n",
       "      <td>1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Chemiker hatte seit Jahren abgelaufene Ampulle...</td>\n",
       "      <td>2915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Insgesamt führt Polizei rund 80 Opfer – 160 vo...</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Unabhängige Opferschutzkommission entschied in...</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Stadtregierung überlässt Nachforschungen im Be...</td>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Die Kutschen sind eine beliebte Attraktion bei...</td>\n",
       "      <td>3589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Wien - Das für viele Österreicher durch den Fe...</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Lediglich am Montag kann es nördlich der Alpen...</td>\n",
       "      <td>5595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Trotz Störungszone am Mittwoch teilweise Tempe...</td>\n",
       "      <td>2915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Am Freitag folgt ein Adriatief. Wien – Wer die...</td>\n",
       "      <td>2737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Zumindest zwischendurch zeigt sich die Sonne –...</td>\n",
       "      <td>2337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Heftige Gewitter im Walgau, Überflutete Straße...</td>\n",
       "      <td>2802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Für Lkw unabhängig von der Wetterlage vorgesch...</td>\n",
       "      <td>1864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Im Nahverkehrsbereich waren es laut Bahnstatis...</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Eine 78-Jährige ist nach über 50 Jahren mit ih...</td>\n",
       "      <td>3219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Ein 50-Jähriger ist angeklagt, da er Flüchtlin...</td>\n",
       "      <td>5165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Opfer brach seinem Peiniger die Nase – Tatverd...</td>\n",
       "      <td>1489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Flüchtlinge profitierten von Ebbe. Ceuta – Run...</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Syrerin im Rücken getroffen. Bratislava/Wien –...</td>\n",
       "      <td>2090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Derzeit sind 209.000 Asylanträge in Bearbeitun...</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Außenminister: \"Dublin-Abkommen funktioniert n...</td>\n",
       "      <td>5471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>In Ungarn sind Flüchtlinge unerwünscht. Dennoc...</td>\n",
       "      <td>7408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Türkeis Ministerpräsident warnt vor einer \"chr...</td>\n",
       "      <td>1805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Neues Flüchtlingsunglück vor Samos. Lesbos – B...</td>\n",
       "      <td>1544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>5.700 kamen am Mittwoch in Slowenien an – Ein ...</td>\n",
       "      <td>9463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Bereits 3.000 Menschen um 6 Uhr angekommen, we...</td>\n",
       "      <td>4292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Nach Abkommen mit der Türkei könnten weitere F...</td>\n",
       "      <td>1604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Platz für rund 1.200 Asylwerber soll im neuen ...</td>\n",
       "      <td>1657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Panorama</td>\n",
       "      <td>1</td>\n",
       "      <td>Laut Polizei hohe Frequenz, Durchreise aber nu...</td>\n",
       "      <td>2452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _class  class                                               text  \\\n",
       "7      Kultur      0  Der Nationalismus in Russland nehme ständig zu...   \n",
       "8      Kultur      0  \"La Rondine\" in der Regie von Rolando Villazon...   \n",
       "10     Kultur      0  47-jährige Dramaturgin folgt auf Bettina Herin...   \n",
       "12     Kultur      0  \"Die stillen Nächte des Ludwig Rainer\" feiert ...   \n",
       "18     Kultur      0  Uraufführung des österreichischen Dramatikers ...   \n",
       "29     Kultur      0  In seinem neuen Kabarettprogramm \"Der Tolerato...   \n",
       "42     Kultur      0  \"Der fliegende Holländer\" im Theater an der Wi...   \n",
       "43     Kultur      0  Die \"Dreigroschenoper \" in der Regie von Keith...   \n",
       "54     Kultur      0  Edler Gesang, greller Humor: Donizettis \"Don P...   \n",
       "66     Kultur      0  Schwarzer Humor im Off-Theater: Das Bernhard-E...   \n",
       "83     Kultur      0  Werner Schwabs \"Fäkaliendrama\" als famose Musi...   \n",
       "88     Kultur      0  Sein \"Werther\"-Solo hat seit der Premiere 1974...   \n",
       "90     Kultur      0  Dusan David Parízek hat für seine Fassung von ...   \n",
       "91     Kultur      0  Vorzeichen für Inszenierung hätten sich aufgru...   \n",
       "93     Kultur      0  Anja Salomonowitz inszeniert im Volx/Margarete...   \n",
       "98     Kultur      0  Die großartigste Hommage an den Dramatiker Hei...   \n",
       "105    Kultur      0  Der 18-Jährige kam nahe dem Gelände des Sziget...   \n",
       "110    Kultur      0  Ob er in die übergroßen Fußstapfen seines Vorg...   \n",
       "113    Kultur      0  Durch das Alpine Museum der Schweiz weht ein f...   \n",
       "136    Kultur      0  In \"Der Nachtmahr\" erschafft der Filmemacher u...   \n",
       "144    Kultur      0  Drama, Herzschmerz, Hausaufgaben – der Mikroko...   \n",
       "148    Kultur      0  Den Lieblingsfilm in einem Satz zu erzählen is...   \n",
       "157    Kultur      0  Nach vier glücklosen Anläufen bekam DiCaprio d...   \n",
       "160    Kultur      0  \"Oskar, Rico und Herzgebreche\" ist die Verfilm...   \n",
       "183    Kultur      0  In Babak Najafis Actionspektakel mit Aaron Eck...   \n",
       "185    Kultur      0  Das Holocaustdrama von László Nemes, mit einem...   \n",
       "188    Kultur      0  Mit seinen klaren, schnörkellosen Filmen um ko...   \n",
       "194    Kultur      0  \"Ant-Man\" blieb vorn – \"Pixels\" und \"Minions\" ...   \n",
       "215    Kultur      0  Unterstützer der Sammlung Alter Musikinstrumen...   \n",
       "216    Kultur      0  Hunderte Objekte illegal exportierten antiken ...   \n",
       "..        ...    ...                                                ...   \n",
       "718  Panorama      1  Vier junge Tschetschenen forderten Mädchen auf...   \n",
       "730  Panorama      1  Drei Beruhigungsspritzen betäubten Tier – 20 F...   \n",
       "732  Panorama      1  Chemiker hatte seit Jahren abgelaufene Ampulle...   \n",
       "752  Panorama      1  Insgesamt führt Polizei rund 80 Opfer – 160 vo...   \n",
       "766  Panorama      1  Unabhängige Opferschutzkommission entschied in...   \n",
       "777  Panorama      1  Stadtregierung überlässt Nachforschungen im Be...   \n",
       "779  Panorama      1  Die Kutschen sind eine beliebte Attraktion bei...   \n",
       "781  Panorama      1  Wien - Das für viele Österreicher durch den Fe...   \n",
       "790  Panorama      1  Lediglich am Montag kann es nördlich der Alpen...   \n",
       "793  Panorama      1  Trotz Störungszone am Mittwoch teilweise Tempe...   \n",
       "798  Panorama      1  Am Freitag folgt ein Adriatief. Wien – Wer die...   \n",
       "802  Panorama      1  Zumindest zwischendurch zeigt sich die Sonne –...   \n",
       "803  Panorama      1  Heftige Gewitter im Walgau, Überflutete Straße...   \n",
       "817  Panorama      1  Für Lkw unabhängig von der Wetterlage vorgesch...   \n",
       "822  Panorama      1  Im Nahverkehrsbereich waren es laut Bahnstatis...   \n",
       "844  Panorama      1  Eine 78-Jährige ist nach über 50 Jahren mit ih...   \n",
       "862  Panorama      1  Ein 50-Jähriger ist angeklagt, da er Flüchtlin...   \n",
       "881  Panorama      1  Opfer brach seinem Peiniger die Nase – Tatverd...   \n",
       "898  Panorama      1  Flüchtlinge profitierten von Ebbe. Ceuta – Run...   \n",
       "901  Panorama      1  Syrerin im Rücken getroffen. Bratislava/Wien –...   \n",
       "907  Panorama      1  Derzeit sind 209.000 Asylanträge in Bearbeitun...   \n",
       "917  Panorama      1  Außenminister: \"Dublin-Abkommen funktioniert n...   \n",
       "920  Panorama      1  In Ungarn sind Flüchtlinge unerwünscht. Dennoc...   \n",
       "924  Panorama      1  Türkeis Ministerpräsident warnt vor einer \"chr...   \n",
       "958  Panorama      1  Neues Flüchtlingsunglück vor Samos. Lesbos – B...   \n",
       "960  Panorama      1  5.700 kamen am Mittwoch in Slowenien an – Ein ...   \n",
       "970  Panorama      1  Bereits 3.000 Menschen um 6 Uhr angekommen, we...   \n",
       "981  Panorama      1  Nach Abkommen mit der Türkei könnten weitere F...   \n",
       "984  Panorama      1  Platz für rund 1.200 Asylwerber soll im neuen ...   \n",
       "999  Panorama      1  Laut Polizei hohe Frequenz, Durchreise aber nu...   \n",
       "\n",
       "     length  \n",
       "7      1732  \n",
       "8      2921  \n",
       "10     1271  \n",
       "12     2210  \n",
       "18     2677  \n",
       "29     7630  \n",
       "42     3002  \n",
       "43     3804  \n",
       "54     2249  \n",
       "66     3041  \n",
       "83     4014  \n",
       "88     6752  \n",
       "90     3668  \n",
       "91     2160  \n",
       "93     2948  \n",
       "98     3940  \n",
       "105     997  \n",
       "110    2405  \n",
       "113    5059  \n",
       "136    6131  \n",
       "144    2353  \n",
       "148     746  \n",
       "157    6027  \n",
       "160     956  \n",
       "183     970  \n",
       "185    5167  \n",
       "188    3992  \n",
       "194    1799  \n",
       "215    4554  \n",
       "216    4127  \n",
       "..      ...  \n",
       "718    4650  \n",
       "730    1380  \n",
       "732    2915  \n",
       "752    2002  \n",
       "766    1047  \n",
       "777    2648  \n",
       "779    3589  \n",
       "781    3215  \n",
       "790    5595  \n",
       "793    2915  \n",
       "798    2737  \n",
       "802    2337  \n",
       "803    2802  \n",
       "817    1864  \n",
       "822    1421  \n",
       "844    3219  \n",
       "862    5165  \n",
       "881    1489  \n",
       "898     962  \n",
       "901    2090  \n",
       "907    1151  \n",
       "917    5471  \n",
       "920    7408  \n",
       "924    1805  \n",
       "958    1544  \n",
       "960    9463  \n",
       "970    4292  \n",
       "981    1604  \n",
       "984    1657  \n",
       "999    2452  \n",
       "\n",
       "[130 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "downsample(corpus1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
